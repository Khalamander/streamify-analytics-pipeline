# ğŸš€ Streamify Analytics Pipeline

A real-time merchant analytics and fraud detection pipeline built with modern data engineering technologies. Features live data processing, advanced ML-based fraud detection, and interactive web dashboard.

## ğŸ“Š Architecture

```mermaid
graph TB
    A[Data Generator] --> B[Kafka Topics]
    B --> C[Spark Streaming]
    C --> D[Fraud Detection]
    C --> E[Analytics Engine]
    D --> F[Fraud Alerts]
    E --> G[Real-time Metrics]
    B --> H[AWS S3 Data Lake]
    H --> I[AWS Glue ETL]
    I --> J[Snowflake Warehouse]
    K[Airflow Orchestration] --> I
    L[Web Dashboard] --> G
    L --> F
```

## ğŸ› ï¸ Tech Stack

- **Streaming**: Apache Kafka, Spark Streaming
- **Cloud**: AWS (S3, Glue, EC2), Snowflake
- **Orchestration**: Apache Airflow
- **Web**: Flask, HTML/CSS/JavaScript
- **Language**: Python 3.x

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Docker & Docker Compose (optional)
- Flask

### 1. Setup
```bash
git clone https://github.com/your-username/streamify-analytics-pipeline.git
cd streamify-analytics-pipeline
pip install -r requirements.txt
```

### 2. Web Dashboard (Recommended)
```bash
python app.py
# Open http://localhost:8080
```

**Features:**
- ğŸ® Interactive controls (Start/Stop/Reset)
- ğŸ“Š Real-time metrics and charts
- ğŸš¨ Live fraud detection with ML scoring
- ğŸ’³ Transaction feed with risk factors

### 3. Full Stack with Docker
```bash
# Start Kafka services
docker-compose up -d zookeeper kafka

# Create topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --create --topic sales_stream --partitions 3 --replication-factor 1
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --create --topic fraud_alerts --partitions 3 --replication-factor 1
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --create --topic analytics_stream --partitions 3 --replication-factor 1

# Start dashboard
python app.py
```

## ğŸ–¥ï¸ Live Dashboard

![Live Demo Screenshot](screenshots/Live%20Demo%20Screenshot.png)

**Real-time Features:**
- Live fraud detection with 5 risk factors
- ML-based scoring (Amount, Velocity, Geographic, Device, Pattern)
- Color-coded alerts (Critical/High/Medium/Low)
- Interactive charts and analytics
- Transaction feed with detailed risk breakdown

## ğŸ” Data Sources

### Real Services
- âœ… **Apache Kafka**: Real message streaming
- âœ… **Faker Library**: Realistic transaction generation
- âœ… **Flask Web Framework**: Production-ready dashboard
- âœ… **Docker Containers**: Real Kafka and Zookeeper

### Mock Services (Cost-Free)
- ğŸ”„ **AWS S3**: Local file storage
- ğŸ”„ **Snowflake**: SQLite database
- ğŸ”„ **AWS Glue**: Code ready for deployment

## ğŸ§ª Testing

### Quick Test
```bash
python scripts/simple_test.py
# Tests: Core functionality, fraud detection, analytics
```

### Comprehensive Demo
```bash
python scripts/demo_pipeline.py
# Shows: Live processing, fraud detection, architecture
```

### Docker Integration
```bash
python scripts/test_docker_components.py
# Tests: Kafka services, web dashboard, data generation
```

## ğŸš¨ Fraud Detection

**Advanced ML-Based System:**
- **5 Risk Factors**: Amount, Velocity, Geographic, Device, Pattern
- **Weighted Scoring**: Each factor has different importance
- **Alert Levels**: Critical, High, Medium, Low
- **Real-time Processing**: Live detection as transactions are generated

**Risk Factors:**
- **Amount Risk**: High-value transaction detection
- **Velocity Risk**: Rapid transaction patterns
- **Geographic Risk**: Impossible travel detection
- **Device Risk**: Device fingerprinting and browser tracking
- **Pattern Risk**: Suspicious payment methods and categories

## ğŸ“ˆ Performance

- **Processing Rate**: 20-50 transactions per minute
- **Response Time**: <100ms for API calls
- **Memory Usage**: <100MB for typical operation
- **Fraud Detection**: <50ms per transaction

## ğŸ”§ Configuration

### Environment Variables
```bash
# Kafka Configuration
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC_SALES=sales_stream
KAFKA_TOPIC_FRAUD=fraud_alerts
KAFKA_TOPIC_ANALYTICS=analytics_stream

# AWS Configuration (Mock for local testing)
AWS_ACCESS_KEY_ID=your_access_key
AWS_SECRET_ACCESS_KEY=your_secret_key
AWS_S3_BUCKET=streamify-data-lake
AWS_REGION=us-east-1

# Snowflake Configuration (Mock for local testing)
SNOWFLAKE_ACCOUNT=your_account
SNOWFLAKE_USER=your_username
SNOWFLAKE_PASSWORD=your_password
SNOWFLAKE_DATABASE=ANALYTICS
SNOWFLAKE_SCHEMA=PUBLIC
SNOWFLAKE_WAREHOUSE=COMPUTE_WH
```

## ğŸ“ Project Structure

```
streamify-analytics-pipeline/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ producer/
â”‚   â”‚   â””â”€â”€ producer.py          # Data generation
â”‚   â””â”€â”€ processor/
â”‚       â”œâ”€â”€ fraud_detector.py    # ML fraud detection
â”‚       â””â”€â”€ analytics_engine.py  # Real-time analytics
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ streamify_analytics_pipeline.py
â”‚   â””â”€â”€ fraud_detection_monitoring.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ simple_test.py
â”‚   â”œâ”€â”€ demo_pipeline.py
â”‚   â””â”€â”€ test_docker_components.py
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ dashboard.html
â”œâ”€â”€ app.py                       # Web dashboard
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ requirements.txt
```

## ğŸš€ Deployment

### Local Development
```bash
python app.py
```

### Production (AWS)
1. Deploy Kafka cluster on EC2
2. Configure S3 buckets for data lake
3. Set up Snowflake warehouse
4. Deploy Airflow on EC2
5. Configure AWS Glue jobs

## ğŸ“Š Monitoring

- **Health Checks**: Service status monitoring
- **Performance Metrics**: Processing rates and latency
- **Fraud Alerts**: Real-time fraud detection results
- **Data Quality**: Transaction validation and error detection

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For questions or issues:
- Create an issue on GitHub
- Check the troubleshooting section
- Review the documentation

---

**Built with â¤ï¸ for modern data engineering and fraud detection**